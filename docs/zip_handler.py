import zipfile, json, os, re
from pathlib import Path

def process_zip_files():
    """docs í´ë”ì˜ ZIP íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ memory.jsonì— í†µí•© ë° 50,000ê°œë¡œ ì¶•ì†Œ"""
    
    memory_file = "docs/memory.json"
    os.makedirs("docs", exist_ok=True)
    
    # ê¸°ì¡´ memory.json ë¡œë“œ
    existing_memory = []
    if os.path.exists(memory_file):
        try:
            with open(memory_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    existing_memory = data
        except:
            existing_memory = []
            
    print(f"ê¸°ì¡´ ë©”ëª¨ë¦¬: {len(existing_memory)}ê°œ í•­ëª©")
    
    # ZIP íŒŒì¼ì„ 'docs' í´ë” ì•ˆì—ì„œ ì°¾ë„ë¡ ê²½ë¡œê°€ ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    zip_files = list(Path("docs").glob("*.zip"))
    
    if not zip_files:
        print("ì²˜ë¦¬í•  ZIP íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (docs/ í´ë”ì— ZIP íŒŒì¼ í™•ì¸ ìš”ë§)")
    
    new_sentences = []
    
    for zip_path in zip_files:
        print(f"\nì²˜ë¦¬ ì¤‘: {zip_path}")
        
        try:
            with zipfile.ZipFile(zip_path, "r") as z:
                for file_name in z.namelist():
                    if file_name.endswith(('.txt', '.json', '.md')):
                        try:
                            with z.open(file_name) as f:
                                content = f.read().decode("utf-8", errors="ignore")
                                if file_name.endswith('.json'):
                                    try:
                                        json_data = json.loads(content)
                                        if isinstance(json_data, list):
                                            new_sentences.extend(json_data)
                                        elif isinstance(json_data, dict):
                                            for value in json_data.values():
                                                if isinstance(value, str) and len(value) > 10:
                                                    new_sentences.append(value)
                                    except:
                                        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                                        new_sentences.extend(extract_sentences_from_text(content))
                                else:
                                    # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
                                    new_sentences.extend(extract_sentences_from_text(content))
                        except Exception as e:
                            print(f"  ì˜¤ë¥˜: {e}")
                            continue
            
        except Exception as e:
            print(f"ZIP íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue
            
    print(f"\nìƒˆë¡œ ì¶”ì¶œëœ ë¬¸ì¥: {len(new_sentences)}ê°œ")
    
    # ë°ì´í„° ì •ë¦¬ ë° ë³‘í•©
    all_sentences = existing_memory + new_sentences
    cleaned_sentences = clean_and_deduplicate(all_sentences)
    
    # ì €ì¥
    try:
        with open(memory_file, "w", encoding="utf-8") as f:
            json.dump(cleaned_sentences, f, ensure_ascii=False, indent=2)
        print(f"âœ… ì™„ë£Œ: {len(cleaned_sentences)}ê°œ ë¬¸ì¥ì´ memory.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")


def extract_sentences_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì¥ ì¶”ì¶œ (í•„í„°ë§ ìµœì†Œí™”, ìµœì†Œ ê¸¸ì´ 5ì)"""
    sentences = []
    
    # í…ìŠ¤íŠ¸ë¥¼ ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    parts = re.split(r'[.!?]\s*', text)
    
    for part in parts:
        # ì¤„ ë°”ê¿ˆ ë° ë‹¤ì¤‘ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
        clean_part = re.sub(r'[\r\n\t]+', ' ', part)
        clean_part = re.sub(r'\s+', ' ', clean_part).strip()
        
        # ğŸ‘‡ ë¬¸ì¥ ê¸¸ì´ ì œí•œì„ 5ìë¡œ ìµœì†Œí™”í•©ë‹ˆë‹¤.
        if 5 <= len(clean_part) <= 300: 
            # ë¶ˆí•„ìš”í•œ ë”°ì˜´í‘œë‚˜ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤.
            if clean_part.startswith('"') and clean_part.endswith('"'):
                clean_part = clean_part[1:-1].strip()
            
            sentences.append(clean_part)
            
    return sentences

def clean_and_deduplicate(sentences):
    """ë¬¸ì¥ ì •ë¦¬ ë° ì¤‘ë³µ ì œê±°, 50,000ê°œë¡œ ì¶•ì†Œ"""
    seen = set()
    cleaned = []
    
    for sentence in sentences:
        if not isinstance(sentence, str):
            sentence = str(sentence)
            
        clean = re.sub(r'\s+', ' ', sentence).strip()
        
        # ğŸ‘‡ ìµœì†Œ ê¸¸ì´ ì œí•œì„ 5ìë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
        if len(clean) < 5 or len(clean) > 500: 
            continue
            
        if clean not in seen:
            seen.add(clean)
            cleaned.append(clean)
            
    # Vercel ë©”ëª¨ë¦¬ í•œê³„ ê·¹ë³µì„ ìœ„í•œ ë°ì´í„° ì¶•ì†Œ
    if len(cleaned) > 50000:
        cleaned = cleaned[-50000:]
        
    return cleaned

if __name__ == "__main__":
    process_zip_files()
